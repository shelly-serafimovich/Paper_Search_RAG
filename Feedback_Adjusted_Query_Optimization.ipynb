{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Notebook Description: Feedback-Adjusted Query Optimization**\n",
    "\n",
    "This notebook explores the impact of feedback-based query refinement on article retrieval quality, comparing the feedback-adjusted method to the expanded query approach. To simulate user feedback, we generate artificial feedback by marking articles with above-average model scores as relevant. This feedback is used to refine the query vector—prioritizing relevant articles and reducing the influence of less relevant ones—to improve retrieval accuracy.\n",
    "\n",
    "For evaluation, we rely on model assessments as the primary metric: three language models rate the relevance of each article's abstract to the query. We use the average of these scores and cosine similarity to measure the effectiveness of retrieval. This analysis highlights how feedback, even when simulated, can dynamically improve the quality of results."
   ],
   "metadata": {
    "id": "9WT8FGT19U-7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#imports\n",
    "!pip install openai==0.28\n",
    "!pip install pinecone cohere openai sentence_transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import ndcg_score\n",
    "import google.generativeai as genai\n",
    "import pinecone\n",
    "import openai\n",
    "import cohere\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n"
   ],
   "metadata": {
    "id": "xpdYco289WjM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set up Pinecone\n",
    "pc = Pinecone(api_key='YOUR-API-KEY')\n",
    "index = pc.Index(\"document-embeddings\")"
   ],
   "metadata": {
    "id": "mY3FCVp79XPi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set up OpenAI, Gemini and Cohere API keys\n",
    "openai.api_key = 'YOUR-API-KEY'\n",
    "co = cohere.Client('YOUR-API-KEY')\n",
    "genai.configure(api_key='YOUR-API-KEY')\n"
   ],
   "metadata": {
    "id": "zbXKf9UH9ZrW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize SentenceTransformer model for embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Function to encode text using SentenceTransformer\n",
    "def encode_text(text):\n",
    "    embeddings = model.encode(text)\n",
    "    return embeddings"
   ],
   "metadata": {
    "id": "x4neCwfB9bS0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Retrieve top K articles from Pinecone\n",
    "def retrieve_articles(query, top_k=5):\n",
    "    query_embedding = encode_text(query)\n",
    "    response = index.query(vector=query_embedding.tolist(), top_k=top_k, include_metadata=True, include_values=True)\n",
    "    articles = [(match['metadata']['title'], match['metadata']['abstract']) for match in response['matches']]\n",
    "    return articles\n",
    "\n",
    "# Evaluate articles using GPT, Cohere, and Gemini\n",
    "def evaluate_articles(query, articles):\n",
    "    gpt_scores, cohere_scores, gemini_scores = [], [], []\n",
    "    for title, abstract in articles:\n",
    "        combined_text = f\"Title: {title}\\nAbstract: {abstract}\"\n",
    "\n",
    "        # OpenAI GPT Score\n",
    "        gpt_score = call_gpt_api(query, combined_text)\n",
    "        gpt_scores.append(gpt_score)\n",
    "\n",
    "        # Cohere Score\n",
    "        cohere_score = call_cohere_api(query, combined_text)\n",
    "        cohere_scores.append(cohere_score)\n",
    "\n",
    "        # Gemini Score\n",
    "        gemini_score = call_gemini_api(query, combined_text)\n",
    "        gemini_scores.append(gemini_score)\n",
    "\n",
    "    avg_scores = [(g + c + a) / 3 for g, c, a in zip(gpt_scores, cohere_scores, gemini_scores)]\n",
    "    return avg_scores\n",
    "\n",
    "# GPT API call\n",
    "def call_gpt_api(query, abstract):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a relevance evaluator for scientific articles. Reply with only a single number between 1 and 10.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {query}\\nArticle Abstract: {abstract}\\nRate the relevance from 1 to 10. Only provide the number as an answer.\"}\n",
    "        ]\n",
    "    )\n",
    "    score_text = response['choices'][0]['message']['content']\n",
    "    return float(score_text.strip())\n",
    "\n",
    "\n",
    "# Cohere API call\n",
    "def call_cohere_api(query, abstract):\n",
    "    response = co.generate(\n",
    "        model=\"command-xlarge-nightly\",\n",
    "        prompt=f\"You are a relevance evaluator for scientific articles. Question: {query}\\nArticle Abstract: {abstract}\\nRate the relevance from 1 to 10. Only provide the number as an answer.\",\n",
    "        max_tokens=10\n",
    "    )\n",
    "    return float(response.generations[0].text.strip())\n",
    "\n",
    "\n",
    "# Gemini API call\n",
    "def call_gemini_api(query, abstract):\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    prompt_text = f\"You are a relevance evaluator for scientific articles. Question: {query}\\nArticle Abstract: {abstract}\\nRate the relevance from 1 to 10. Only provide the number as an answer.\"\n",
    "    response = model.generate_content(prompt_text)\n",
    "    return float(response.text)\n",
    "\n",
    "\n",
    "# Query expansion using GPT\n",
    "def expand_query(query):\n",
    "    # Generate expanded terms related to the original query using GPT\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in data science and information retrieval.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Provide additional keywords or phrases that could be incorporated into the following query to refine or broaden it, but do not answer the question. Return a concise list of relevant terms or phrases only. Query: '{query}'\"}\n",
    "        ]\n",
    "    )\n",
    "    expanded_terms = response['choices'][0]['message']['content'].strip()\n",
    "    expanded_query = f\"{query} {expanded_terms}\"  # Combine original query with expanded terms\n",
    "    return expanded_query\n",
    "\n"
   ],
   "metadata": {
    "id": "l7BdDWCQ9d5Z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to get the top 5 articles based on model score, combining original and expanded queries\n",
    "def get_top_5_articles(query, index, top_k=5):\n",
    "    # Retrieve articles and scores for the original query\n",
    "    original_articles = retrieve_articles(query, top_k)\n",
    "    original_scores = evaluate_articles(query, original_articles)\n",
    "\n",
    "    # Retrieve articles and scores for the expanded query\n",
    "    expanded_query = expand_query(query)\n",
    "    expanded_articles = retrieve_articles(expanded_query, top_k)\n",
    "    expanded_scores = evaluate_articles(query, expanded_articles)\n",
    "\n",
    "    # Combine results from original and expanded queries\n",
    "    combined_articles = []\n",
    "    for i, (title, abstract) in enumerate(original_articles):\n",
    "        combined_articles.append({\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract,\n",
    "            \"model_score\": original_scores[i],\n",
    "            \"source_query\": \"original\"\n",
    "        })\n",
    "\n",
    "    for i, (title, abstract) in enumerate(expanded_articles):\n",
    "        # Avoid duplicates\n",
    "        if title not in [article[\"title\"] for article in combined_articles]:\n",
    "            combined_articles.append({\n",
    "                \"title\": title,\n",
    "                \"abstract\": abstract,\n",
    "                \"model_score\": expanded_scores[i],\n",
    "                \"source_query\": \"expanded\"\n",
    "            })\n",
    "\n",
    "    # Sort combined articles by model score and select the top 5\n",
    "    top_5_articles = sorted(combined_articles, key=lambda x: x[\"model_score\"], reverse=True)[:5]\n",
    "\n",
    "    # Format the top 5 articles in the same structure as the original code\n",
    "    formatted_articles = [(article[\"title\"], article[\"abstract\"]) for article in top_5_articles]\n",
    "    return formatted_articles, [article[\"model_score\"] for article in top_5_articles]  # Return titles, abstracts, and scores\n",
    "\n"
   ],
   "metadata": {
    "id": "E9guRxOW9iKw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to refine the query vector based on feedback\n",
    "def refine_query_with_feedback(article_embeddings, feedback, weight_relevance=1.0, weight_irrelevance=0.1):\n",
    "    # Separate embeddings based on feedback\n",
    "    relevant_embeddings = [emb for emb, fb in zip(article_embeddings, feedback) if fb == 1]\n",
    "    irrelevant_embeddings = [emb for emb, fb in zip(article_embeddings, feedback) if fb == 0]\n",
    "\n",
    "    # Compute the refined query vector\n",
    "    if relevant_embeddings:\n",
    "        relevant_vector = np.mean(relevant_embeddings, axis=0) * weight_relevance\n",
    "    else:\n",
    "        # Fallback if no relevant feedback is given\n",
    "        relevant_vector = np.mean(article_embeddings, axis=0)\n",
    "\n",
    "    # Optionally adjust based on irrelevant embeddings\n",
    "    if irrelevant_embeddings:\n",
    "        irrelevant_vector = np.mean(irrelevant_embeddings, axis=0) * weight_irrelevance\n",
    "        final_vector = relevant_vector - irrelevant_vector  # Subtract irrelevant components\n",
    "    else:\n",
    "        final_vector = relevant_vector\n",
    "\n",
    "    return final_vector\n"
   ],
   "metadata": {
    "id": "C0eVfA649m4X"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to retrieve new articles using the refined vector\n",
    "def retrieve_improved_results(final_vector, index, top_k=5):\n",
    "    # Query Pinecone using the refined vector\n",
    "    query_result = index.query(vector=final_vector.tolist(), top_k=top_k, include_metadata=True, include_values=True)\n",
    "\n",
    "    # Extract metadata from results and structure in the same format\n",
    "    articles = []\n",
    "    for match in query_result['matches']:\n",
    "        title = match['metadata'].get('title', 'No title available')\n",
    "        abstract = match['metadata'].get('abstract', 'No abstract available')\n",
    "        articles.append((title, abstract))  # Format as tuple for consistency\n",
    "\n",
    "    return articles\n"
   ],
   "metadata": {
    "id": "9nk9R8Sz9qrJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "feedback_csv_file = \"feedback_vs_expanded_results.csv\"\n",
    "\n",
    "# Check if CSV exists and load it if it does\n",
    "if os.path.exists(feedback_csv_file):\n",
    "    results_df = pd.read_csv(feedback_csv_file)\n",
    "else:\n",
    "    # Initialize an empty DataFrame if the CSV does not exist\n",
    "    columns = [\n",
    "        \"query\", \"expanded_query\", \"title\", \"abstract\",\n",
    "        \"expanded_score\", \"feedback_adjusted_score\", \"cosine_similarity\",\n",
    "        \"source_query\", \"overlap_count\"\n",
    "    ]\n",
    "    results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(query_embedding, abstract_embedding):\n",
    "    return cosine_similarity([query_embedding], [abstract_embedding])[0][0]\n",
    "\n",
    "# Function to compare expanded method vs. feedback-adjusted method\n",
    "def test_feedback_vs_expanded(questions, top_k=5):\n",
    "    global results_df\n",
    "\n",
    "    for query in questions:\n",
    "        # Retrieve articles and scores using the expanded query\n",
    "        print(f\"Running expanded query retrieval for: {query}\")\n",
    "        expanded_articles, expanded_scores = get_top_5_articles(query, index)\n",
    "        avg_expanded_score = np.mean(expanded_scores)\n",
    "        query_embedding = encode_text(query)  # Embedding of the original query\n",
    "\n",
    "        # Track articles from expanded method for overlap count\n",
    "        expanded_titles = {title for title, _ in expanded_articles}\n",
    "        all_articles = {}\n",
    "\n",
    "        # Process expanded query articles\n",
    "        for i, (title, abstract) in enumerate(expanded_articles):\n",
    "            abstract_embedding = encode_text(abstract)\n",
    "            cosine_sim = calculate_cosine_similarity(query_embedding, abstract_embedding)\n",
    "            all_articles[title] = {\n",
    "                \"query\": query,\n",
    "                \"expanded_query\": expand_query(query),\n",
    "                \"title\": title,\n",
    "                \"abstract\": abstract,\n",
    "                \"expanded_score\": expanded_scores[i],\n",
    "                \"cosine_similarity\": cosine_sim,\n",
    "                \"source_query\": \"expanded\",\n",
    "                \"feedback_adjusted_score\": None\n",
    "            }\n",
    "\n",
    "        # Feedback adjustment\n",
    "        article_embeddings = [encode_text(article[1]) for article in expanded_articles]\n",
    "        feedback = [1 if score > avg_expanded_score else 0 for score in expanded_scores]  # Generate sample feedback\n",
    "        final_vector = refine_query_with_feedback(article_embeddings, feedback)\n",
    "\n",
    "        # Retrieve feedback-adjusted articles and evaluate\n",
    "        feedback_articles = retrieve_improved_results(final_vector, index, top_k)\n",
    "        feedback_scores = evaluate_articles(query, feedback_articles)\n",
    "\n",
    "        # Process feedback-adjusted articles, checking for overlap\n",
    "        for i, (title, abstract) in enumerate(feedback_articles):\n",
    "            abstract_embedding = encode_text(abstract)\n",
    "            cosine_sim = calculate_cosine_similarity(query_embedding, abstract_embedding)\n",
    "            source_query = \"feedback_adjusted\" if title not in expanded_titles else \"overlap\"\n",
    "            all_articles[title] = {\n",
    "                \"query\": query,\n",
    "                \"expanded_query\": expand_query(query),\n",
    "                \"title\": title,\n",
    "                \"abstract\": abstract,\n",
    "                \"expanded_score\": expanded_scores[i] if source_query == \"overlap\" else None,\n",
    "                \"cosine_similarity\": cosine_sim,\n",
    "                \"source_query\": source_query,\n",
    "                \"feedback_adjusted_score\": feedback_scores[i]\n",
    "            }\n",
    "\n",
    "        # Add results to DataFrame\n",
    "        for article_data in all_articles.values():\n",
    "            new_row = pd.DataFrame([article_data])\n",
    "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        # Calculate overlap count\n",
    "        overlap_count = sum(1 for article in all_articles.values() if article[\"source_query\"] == \"overlap\")\n",
    "\n",
    "        # Save intermediate results to the CSV file\n",
    "        results_df.to_csv(feedback_csv_file, index=False)\n",
    "        print(f\"Results saved to CSV after query: {query}\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# List of questions to test\n",
    "questions = [\n",
    "    \"What are the latest techniques for explainability in deep neural networks?\",\n",
    "    \"How is transfer learning being applied in medical imaging analysis?\",\n",
    "    \"What are the advancements in handling class imbalance in supervised learning?\",\n",
    "    \"How can reinforcement learning improve autonomous vehicle navigation?\",\n",
    "    \"What methods exist for detecting outliers in financial time series?\",\n",
    "    \"What are recent innovations in synthetic data generation for NLP?\",\n",
    "    \"How is unsupervised learning being used in anomaly detection?\",\n",
    "    \"What are the latest approaches to causal inference in data science?\",\n",
    "    \"How is AI being used to optimize supply chain management?\",\n",
    "    \"What are novel techniques for feature engineering in time series data?\",\n",
    "    \"How can GANs (Generative Adversarial Networks) improve image resolution?\",\n",
    "    \"What role does data augmentation play in small dataset training?\",\n",
    "    \"How is federated learning enhancing privacy in healthcare applications?\",\n",
    "    \"What are effective methods for hyperparameter tuning in deep learning?\",\n",
    "    \"How can active learning reduce labeling costs in supervised learning?\",\n",
    "    \"What are the advancements in dimensionality reduction techniques for visualization?\",\n",
    "    \"How is NLP being used to analyze sentiment in financial news?\",\n",
    "    \"What methods are effective for handling missing data in datasets?\",\n",
    "    \"How is transfer learning improving outcomes in drug discovery research?\",\n",
    "    \"What are the latest machine learning techniques for predictive maintenance?\"\n",
    "]\n",
    "\n",
    "# Run the test function with each question, waiting 35 seconds between each to manage API rate limits\n",
    "for question in questions:\n",
    "    print(f\"Running expanded vs feedback-adjusted comparison for question: {question}\")\n",
    "    results_df = test_feedback_vs_expanded([question])  # Test with each question\n",
    "    print(f\"Completed query for: {question}\")\n",
    "    print(\"Waiting 35 seconds before the next run...\")\n",
    "    time.sleep(35)\n",
    "\n",
    "print(\"All queries completed.\")\n"
   ],
   "metadata": {
    "id": "3alP9tWs9wKd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Table of results and statistics of performances in the top 5:**"
   ],
   "metadata": {
    "id": "M2v67_zH_WeO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results_df = pd.read_csv(\"feedback_vs_expanded_results.csv\")\n",
    "\n",
    "# Group by query to analyze each query individually\n",
    "query_groups = results_df.groupby('query')\n",
    "\n",
    "# Initialize a list to store counts of new feedback articles per query\n",
    "feedback_counts = []\n",
    "\n",
    "for query, group in query_groups:\n",
    "    # Sort by model score first, and use cosine similarity as a tiebreaker\n",
    "    group['final_score'] = group[['expanded_score', 'feedback_adjusted_score']].max(axis=1)  # Highest score\n",
    "    top_5 = group.sort_values(by=['final_score', 'cosine_similarity'], ascending=[False, False]).head(5)\n",
    "\n",
    "    # Count the number of new articles from the feedback-adjusted method in the top 5\n",
    "    feedback_count = (top_5['source_query'] == 'feedback_adjusted').sum()\n",
    "    feedback_counts.append(feedback_count)\n",
    "\n",
    "    # Print results for each query\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Top 5 Articles:\")\n",
    "    print(top_5[['title', 'final_score', 'cosine_similarity', 'source_query']])\n",
    "    print(f\"Number of new feedback-adjusted articles in top 5: {feedback_count}\\n\")\n",
    "\n",
    "# Calculate and print the average count of feedback-adjusted articles in the top 5 across all queries\n",
    "average_feedback_count = sum(feedback_counts) / len(feedback_counts)\n",
    "print(f\"Average number of new feedback-adjusted articles in the top 5 across all queries: {average_feedback_count}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnIgckQ3wJhV",
    "outputId": "74ffac42-4d62-4cf3-e361-cd5b0c09073d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Query: How can GANs (Generative Adversarial Networks) improve image resolution?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "76            Infrared Image Super-Resolution via GAN     9.666667   \n",
      "73  Generative Adversarial Networks for Image Supe...     9.333333   \n",
      "75  A Generative Model for Hallucinating Diverse V...     9.333333   \n",
      "78  Details or Artifacts: A Locally Discriminative...     9.333333   \n",
      "74  A General Method to Incorporate Spatial Inform...     9.000000   \n",
      "\n",
      "    cosine_similarity       source_query  \n",
      "76           0.648041            overlap  \n",
      "73           0.728315            overlap  \n",
      "75           0.702885            overlap  \n",
      "78           0.693186  feedback_adjusted  \n",
      "74           0.732697            overlap  \n",
      "Number of new feedback-adjusted articles in top 5: 1\n",
      "\n",
      "Query: How can reinforcement learning improve autonomous vehicle navigation?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "23  Evaluation of Safety Constraints in Autonomous...     9.333333   \n",
      "27  Reinforcement Learning Based Safe Decision Mak...     9.333333   \n",
      "22  Benchmarking Reinforcement Learning Techniques...     9.000000   \n",
      "24  A Survey of Deep Reinforcement Learning Algori...     9.000000   \n",
      "25                         Learning to Drive in a Day     9.000000   \n",
      "\n",
      "    cosine_similarity       source_query  \n",
      "23           0.733965            overlap  \n",
      "27           0.684163  feedback_adjusted  \n",
      "22           0.701792           expanded  \n",
      "24           0.695473            overlap  \n",
      "25           0.685675            overlap  \n",
      "Number of new feedback-adjusted articles in top 5: 1\n",
      "\n",
      "Query: How is AI being used to optimize supply chain management?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "58  Implementing Reinforcement Learning Algorithms...     9.333333   \n",
      "57  Optimizing Inventory Routing: A Decision-Focus...     9.333333   \n",
      "64     Deep Controlled Learning for Inventory Control     9.000000   \n",
      "62  Comparing Deep Reinforcement Learning Algorith...     8.666667   \n",
      "63  Learning General Inventory Management Policy f...     8.666667   \n",
      "\n",
      "    cosine_similarity       source_query  \n",
      "58           0.629852            overlap  \n",
      "57           0.579098            overlap  \n",
      "64           0.529778  feedback_adjusted  \n",
      "62           0.597366  feedback_adjusted  \n",
      "63           0.577061  feedback_adjusted  \n",
      "Number of new feedback-adjusted articles in top 5: 3\n",
      "\n",
      "Query: How is federated learning enhancing privacy in healthcare applications?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "87  Differential Privacy-enabled Federated Learnin...     9.666667   \n",
      "89  Privacy Risks Analysis and Mitigation in Feder...     9.000000   \n",
      "88  Federated Learning in Healthcare: Model Miscon...     9.000000   \n",
      "90  Anonymizing Data for Privacy-Preserving Federa...     9.000000   \n",
      "92  Vision Through the Veil: Differential Privacy ...     9.000000   \n",
      "\n",
      "    cosine_similarity       source_query  \n",
      "87           0.671609            overlap  \n",
      "89           0.761555            overlap  \n",
      "88           0.752621            overlap  \n",
      "90           0.734121            overlap  \n",
      "92           0.725775  feedback_adjusted  \n",
      "Number of new feedback-adjusted articles in top 5: 1\n",
      "\n",
      "Query: How is transfer learning being applied in medical imaging analysis?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "6   Deep transfer learning for detecting Covid-19,...     9.666667   \n",
      "14  DenResCov-19: A deep transfer learning network...     9.333333   \n",
      "7   What Makes Transfer Learning Work For Medical ...     9.000000   \n",
      "9   Modality-bridge Transfer Learning for Medical ...     9.000000   \n",
      "8   Supervised Transfer Learning at Scale for Medi...     9.000000   \n",
      "\n",
      "    cosine_similarity       source_query  \n",
      "6            0.627158            overlap  \n",
      "14           0.417544  feedback_adjusted  \n",
      "7            0.720322           expanded  \n",
      "9            0.694051           expanded  \n",
      "8            0.683767           expanded  \n",
      "Number of new feedback-adjusted articles in top 5: 1\n",
      "\n",
      "Query: How is unsupervised learning being used in anomaly detection?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "42  A Bayesian Ensemble for Unsupervised Anomaly D...     9.333333   \n",
      "43  Elsa: Energy-based learning for semi-supervise...     9.000000   \n",
      "44  Transfer Learning from an Auxiliary Discrimina...     9.000000   \n",
      "46  Unsupervised anomaly detection algorithms on r...     9.000000   \n",
      "45  Anomaly Detection by Recombining Gated Unsuper...     9.000000   \n",
      "\n",
      "    cosine_similarity source_query  \n",
      "42           0.627673      overlap  \n",
      "43           0.667234     expanded  \n",
      "44           0.651183     expanded  \n",
      "46           0.639924     expanded  \n",
      "45           0.638342     expanded  \n",
      "Number of new feedback-adjusted articles in top 5: 0\n",
      "\n",
      "Query: What are novel techniques for feature engineering in time series data?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "65  Feature Programming for Multivariate Time Seri...     8.666667   \n",
      "66  AutoFITS: Automatic Feature Engineering for Ir...     8.666667   \n",
      "70  VEST: Automatic Feature Engineering for Foreca...     8.666667   \n",
      "67  Forecasting large collections of time series: ...     7.333333   \n",
      "68     catch22: CAnonical Time-series CHaracteristics     7.000000   \n",
      "\n",
      "    cosine_similarity       source_query  \n",
      "65           0.712226            overlap  \n",
      "66           0.669768            overlap  \n",
      "70           0.612134  feedback_adjusted  \n",
      "67           0.647258           expanded  \n",
      "68           0.669908           expanded  \n",
      "Number of new feedback-adjusted articles in top 5: 1\n",
      "\n",
      "Query: What are recent innovations in synthetic data generation for NLP?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "36  On LLMs-Driven Synthetic Data Generation, Cura...     8.666667   \n",
      "35  Generative AI for Synthetic Data Generation: M...     8.666667   \n",
      "40  Data Generation using Large Language Models fo...     8.333333   \n",
      "37  Does Synthetic Data Make Large Language Models...     8.000000   \n",
      "41  Better Synthetic Data by Retrieving and Transf...     8.000000   \n",
      "\n",
      "    cosine_similarity       source_query  \n",
      "36           0.727660            overlap  \n",
      "35           0.657761            overlap  \n",
      "40           0.599047  feedback_adjusted  \n",
      "37           0.635775            overlap  \n",
      "41           0.593405  feedback_adjusted  \n",
      "Number of new feedback-adjusted articles in top 5: 2\n",
      "\n",
      "Query: What are the advancements in handling class imbalance in supervised learning?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "15  Review of Methods for Handling Class-Imbalance...     9.333333   \n",
      "16  An Empirical Analysis of the Efficacy of Diffe...     9.333333   \n",
      "17  A Survey of Methods for Managing the Classific...     9.000000   \n",
      "18     Rethinking Class Imbalance in Machine Learning     8.333333   \n",
      "19  Influence-Balanced Loss for Imbalanced Visual ...     8.333333   \n",
      "\n",
      "    cosine_similarity source_query  \n",
      "15           0.705577      overlap  \n",
      "16           0.679003      overlap  \n",
      "17           0.663239      overlap  \n",
      "18           0.719706     expanded  \n",
      "19           0.703907     expanded  \n",
      "Number of new feedback-adjusted articles in top 5: 0\n",
      "\n",
      "Query: What are the latest approaches to causal inference in data science?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "53  A Survey on Causal Discovery: Theory and Practice     9.000000   \n",
      "54  A Survey on Causal Discovery Methods for I.I.D...     9.000000   \n",
      "52  A Survey of Learning Causality with Data: Prob...     8.666667   \n",
      "51  Data-Driven Causal Effect Estimation Based on ...     8.666667   \n",
      "55              A Primer on Causality in Data Science     6.666667   \n",
      "\n",
      "    cosine_similarity source_query  \n",
      "53           0.695041      overlap  \n",
      "54           0.679723      overlap  \n",
      "52           0.637679      overlap  \n",
      "51           0.636509      overlap  \n",
      "55           0.673508     expanded  \n",
      "Number of new feedback-adjusted articles in top 5: 0\n",
      "\n",
      "Query: What are the latest techniques for explainability in deep neural networks?\n",
      "Top 5 Articles:\n",
      "                                               title  final_score  \\\n",
      "0  Explaining Deep Neural Networks and Beyond: A ...     9.333333   \n",
      "1  Gradient based Feature Attribution in Explaina...     9.000000   \n",
      "2  Robust Explainability: A Tutorial on Gradient-...     8.666667   \n",
      "3  Explaining Explanations: An Overview of Interp...     8.000000   \n",
      "4                    Explaining Deep Neural Networks     7.333333   \n",
      "\n",
      "   cosine_similarity source_query  \n",
      "0           0.725217      overlap  \n",
      "1           0.716860      overlap  \n",
      "2           0.785365      overlap  \n",
      "3           0.629024      overlap  \n",
      "4           0.739407     expanded  \n",
      "Number of new feedback-adjusted articles in top 5: 0\n",
      "\n",
      "Query: What methods exist for detecting outliers in financial time series?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "30  A review on outlier/anomaly detection in time ...     9.000000   \n",
      "28                  Outliers in dynamic factor models     8.666667   \n",
      "29  Machine learning based forecasting of signific...     8.666667   \n",
      "31  Feedforward Neural Network for Time Series Ano...     6.666667   \n",
      "33  Outliagnostics: Visualizing Temporal Discrepan...     6.666667   \n",
      "\n",
      "    cosine_similarity       source_query  \n",
      "30           0.772433            overlap  \n",
      "28           0.675120            overlap  \n",
      "29           0.656835            overlap  \n",
      "31           0.634165           expanded  \n",
      "33           0.632289  feedback_adjusted  \n",
      "Number of new feedback-adjusted articles in top 5: 1\n",
      "\n",
      "Query: What role does data augmentation play in small dataset training?\n",
      "Top 5 Articles:\n",
      "                                                title  final_score  \\\n",
      "79  Smart Augmentation - Learning an Optimal Data ...     9.333333   \n",
      "80  How Much Data Are Augmentations Worth? An Inve...     9.000000   \n",
      "85  DualAug: Exploiting Additional Heavy Augmentat...     8.666667   \n",
      "81  Further advantages of data augmentation on con...     8.333333   \n",
      "82  Research Trends and Applications of Data Augme...     8.000000   \n",
      "\n",
      "    cosine_similarity       source_query  \n",
      "79           0.600948            overlap  \n",
      "80           0.669494            overlap  \n",
      "85           0.639668  feedback_adjusted  \n",
      "81           0.632378           expanded  \n",
      "82           0.644702           expanded  \n",
      "Number of new feedback-adjusted articles in top 5: 1\n",
      "\n",
      "Average number of new feedback-adjusted articles in the top 5 across all queries: 0.9230769230769231\n"
     ]
    }
   ]
  }
 ]
}